{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "744b4032",
   "metadata": {},
   "source": [
    "# Comprehensive Exploratory Data Analysis (EDA) - Iris Dataset\n",
    "## ML Course Viva Demonstration\n",
    "\n",
    "**Author:** EDA Demonstration  \n",
    "**Dataset:** Iris Dataset from sklearn  \n",
    "**Objective:** Perform thorough exploratory data analysis covering all fundamental EDA techniques\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. Data Import & Preprocessing\n",
    "2. Data Distribution Analysis\n",
    "3. Data Visualization (Diverse Types)\n",
    "4. Data Filtering Techniques\n",
    "5. Statistical Analysis (Correlation & Covariance)\n",
    "6. Sampling Demonstrations\n",
    "7. Multiclass Classification Data Preparation\n",
    "8. Summary & Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5502c4e9",
   "metadata": {},
   "source": [
    "---\n",
    "## SECTION 1: Data Import & Preprocessing\n",
    "\n",
    "In this section, we will:\n",
    "- Import all necessary libraries for EDA\n",
    "- Load the Iris dataset from sklearn\n",
    "- Perform basic data exploration\n",
    "- Check for missing values and data quality\n",
    "- Understand the structure of our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28771da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.datasets import load_iris\n",
    "import warnings\n",
    "\n",
    "# Configure visualization settings\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2632da66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "df['species'] = iris.target\n",
    "df['species_name'] = df['species'].map({0: 'setosa', 1: 'versicolor', 2: 'virginica'})\n",
    "\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"\\nDataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f04781",
   "metadata": {},
   "source": [
    "### 1.1 Basic Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a6a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"=\" * 80)\n",
    "print(\"FIRST 10 ROWS OF THE DATASET\")\n",
    "print(\"=\" * 80)\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e30047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display last few rows\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"LAST 5 ROWS OF THE DATASET\")\n",
    "print(\"=\" * 80)\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407d88ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset information\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\" * 80)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df761c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STATISTICAL SUMMARY OF NUMERICAL FEATURES\")\n",
    "print(\"=\" * 80)\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fa335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape and dimensions\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATASET DIMENSIONS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Number of rows (samples): {df.shape[0]}\")\n",
    "print(f\"Number of columns (features): {df.shape[1]}\")\n",
    "print(f\"\\nFeature names: {list(df.columns)}\")\n",
    "print(f\"\\nData types:\\n{df.dtypes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f98ed09",
   "metadata": {},
   "source": [
    "### 1.2 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936d05f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"=\" * 80)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values)\n",
    "\n",
    "if missing_values.sum() == 0:\n",
    "    print(\"\\n✓ No missing values detected in the dataset!\")\n",
    "else:\n",
    "    print(f\"\\nTotal missing values: {missing_values.sum()}\")\n",
    "    print(\"\\nPercentage of missing values:\")\n",
    "    print((missing_values / len(df)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdcd83f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional data quality checks\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA QUALITY CHECKS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Duplicate rows: {df.duplicated().sum()}\")\n",
    "print(f\"Unique species: {df['species_name'].nunique()}\")\n",
    "print(f\"\\nSpecies distribution:\\n{df['species_name'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e8b2ed",
   "metadata": {},
   "source": [
    "### 1.3 Data Type Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cd0835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify and display data types\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA TYPE VERIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for col in df.columns:\n",
    "    print(f\"{col:30s} -> {df[col].dtype}\")\n",
    "\n",
    "print(\"\\n✓ All numerical features are float64 (appropriate for analysis)\")\n",
    "print(\"✓ Target variable is properly encoded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211f800f",
   "metadata": {},
   "source": [
    "---\n",
    "## SECTION 2: Data Distribution Analysis\n",
    "\n",
    "Understanding the distribution of data is crucial for:\n",
    "- Identifying patterns and anomalies\n",
    "- Understanding class balance\n",
    "- Detecting outliers\n",
    "- Making informed decisions about preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2b62e7",
   "metadata": {},
   "source": [
    "### 2.1 Class Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d2057d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class distribution\n",
    "print(\"=\" * 80)\n",
    "print(\"CLASS DISTRIBUTION ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "class_counts = df['species_name'].value_counts()\n",
    "print(\"\\nAbsolute counts:\")\n",
    "print(class_counts)\n",
    "\n",
    "print(\"\\nPercentage distribution:\")\n",
    "class_percentages = (class_counts / len(df)) * 100\n",
    "print(class_percentages)\n",
    "\n",
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar plot\n",
    "axes[0].bar(class_counts.index, class_counts.values, color=['#FF6B6B', '#4ECDC4', '#45B7D1'])\n",
    "axes[0].set_title('Class Distribution (Count)', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Species', fontsize=12)\n",
    "axes[0].set_ylabel('Count', fontsize=12)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Pie chart\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1']\n",
    "axes[1].pie(class_counts.values, labels=class_counts.index, autopct='%1.1f%%',\n",
    "            colors=colors, startangle=90, textprops={'fontsize': 11})\n",
    "axes[1].set_title('Class Distribution (Percentage)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Dataset is perfectly balanced with 50 samples per class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e7941b",
   "metadata": {},
   "source": [
    "### 2.2 Feature Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8258d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary by feature\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE-WISE STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "feature_cols = iris.feature_names\n",
    "for col in feature_cols:\n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Mean: {df[col].mean():.3f}\")\n",
    "    print(f\"  Median: {df[col].median():.3f}\")\n",
    "    print(f\"  Std Dev: {df[col].std():.3f}\")\n",
    "    print(f\"  Min: {df[col].min():.3f}\")\n",
    "    print(f\"  Max: {df[col].max():.3f}\")\n",
    "    print(f\"  Range: {df[col].max() - df[col].min():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473c0774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions with histograms\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(feature_cols):\n",
    "    axes[idx].hist(df[col], bins=20, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "    axes[idx].axvline(df[col].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[col].mean():.2f}')\n",
    "    axes[idx].axvline(df[col].median(), color='green', linestyle='--', linewidth=2, label=f'Median: {df[col].median():.2f}')\n",
    "    axes[idx].set_title(f'Distribution of {col}', fontsize=13, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col, fontsize=11)\n",
    "    axes[idx].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3091114",
   "metadata": {},
   "source": [
    "### 2.3 Outlier Detection using Box Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d44eaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for outlier detection\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(feature_cols):\n",
    "    bp = axes[idx].boxplot(df[col], vert=True, patch_artist=True,\n",
    "                           boxprops=dict(facecolor='lightblue', color='navy'),\n",
    "                           whiskerprops=dict(color='navy'),\n",
    "                           capprops=dict(color='navy'),\n",
    "                           medianprops=dict(color='red', linewidth=2))\n",
    "    axes[idx].set_title(f'Box Plot: {col}', fontsize=13, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Value', fontsize=11)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12c8681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers using IQR method\n",
    "print(\"=\" * 80)\n",
    "print(\"OUTLIER DETECTION (IQR Method)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for col in feature_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    \n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Q1 (25th percentile): {Q1:.3f}\")\n",
    "    print(f\"  Q3 (75th percentile): {Q3:.3f}\")\n",
    "    print(f\"  IQR: {IQR:.3f}\")\n",
    "    print(f\"  Lower bound: {lower_bound:.3f}\")\n",
    "    print(f\"  Upper bound: {upper_bound:.3f}\")\n",
    "    print(f\"  Number of outliers: {len(outliers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30c0503",
   "metadata": {},
   "source": [
    "### 2.4 Distribution by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814d284e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of features across different species\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(feature_cols):\n",
    "    for species in df['species_name'].unique():\n",
    "        species_data = df[df['species_name'] == species][col]\n",
    "        axes[idx].hist(species_data, bins=15, alpha=0.6, label=species, edgecolor='black')\n",
    "    \n",
    "    axes[idx].set_title(f'Distribution of {col} by Species', fontsize=13, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col, fontsize=11)\n",
    "    axes[idx].set_ylabel('Frequency', fontsize=11)\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51be06d1",
   "metadata": {},
   "source": [
    "---\n",
    "## SECTION 3: Data Visualization (Diverse Types)\n",
    "\n",
    "Visualization is key to understanding patterns, relationships, and insights in data.\n",
    "We will create multiple types of visualizations to explore the dataset from different angles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e702d60a",
   "metadata": {},
   "source": [
    "### 3.1 Scatter Plots - Feature Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc64561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Sepal Length vs Sepal Width\n",
    "plt.figure(figsize=(10, 7))\n",
    "colors = {'setosa': '#FF6B6B', 'versicolor': '#4ECDC4', 'virginica': '#45B7D1'}\n",
    "\n",
    "for species in df['species_name'].unique():\n",
    "    species_data = df[df['species_name'] == species]\n",
    "    plt.scatter(species_data['sepal length (cm)'], species_data['sepal width (cm)'],\n",
    "               label=species, alpha=0.7, s=100, color=colors[species], edgecolors='black')\n",
    "\n",
    "plt.title('Sepal Length vs Sepal Width by Species', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Sepal Length (cm)', fontsize=13)\n",
    "plt.ylabel('Sepal Width (cm)', fontsize=13)\n",
    "plt.legend(title='Species', fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa4609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Petal Length vs Petal Width\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "for species in df['species_name'].unique():\n",
    "    species_data = df[df['species_name'] == species]\n",
    "    plt.scatter(species_data['petal length (cm)'], species_data['petal width (cm)'],\n",
    "               label=species, alpha=0.7, s=100, color=colors[species], edgecolors='black')\n",
    "\n",
    "plt.title('Petal Length vs Petal Width by Species', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Petal Length (cm)', fontsize=13)\n",
    "plt.ylabel('Petal Width (cm)', fontsize=13)\n",
    "plt.legend(title='Species', fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22e2c88",
   "metadata": {},
   "source": [
    "### 3.2 Pair Plot / Scatter Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c3b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive pair plot\n",
    "pair_plot = sns.pairplot(df, hue='species_name', palette=colors, \n",
    "                         diag_kind='kde', height=2.5, aspect=1.2,\n",
    "                         plot_kws={'alpha': 0.6, 's': 50, 'edgecolor': 'black'},\n",
    "                         diag_kws={'alpha': 0.7})\n",
    "pair_plot.fig.suptitle('Pair Plot: All Features by Species', y=1.02, fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e1abbc",
   "metadata": {},
   "source": [
    "### 3.3 Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6bda59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix for numerical features\n",
    "correlation_matrix = df[feature_cols].corr()\n",
    "\n",
    "# Create heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=2, cbar_kws={\"shrink\": 0.8},\n",
    "            fmt='.3f', vmin=-1, vmax=1)\n",
    "plt.title('Correlation Heatmap - Iris Features', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed45ce6b",
   "metadata": {},
   "source": [
    "### 3.4 Violin Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e716fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violin plots for all features\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(feature_cols):\n",
    "    sns.violinplot(data=df, x='species_name', y=col, ax=axes[idx], palette=colors)\n",
    "    axes[idx].set_title(f'Violin Plot: {col} by Species', fontsize=13, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Species', fontsize=11)\n",
    "    axes[idx].set_ylabel(col, fontsize=11)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53acd59e",
   "metadata": {},
   "source": [
    "### 3.5 KDE (Kernel Density Estimation) Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186958bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE plots for feature distributions\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(feature_cols):\n",
    "    for species in df['species_name'].unique():\n",
    "        species_data = df[df['species_name'] == species][col]\n",
    "        axes[idx].hist(species_data, bins=20, alpha=0.3, label=species, density=True, color=colors[species])\n",
    "        species_data.plot(kind='kde', ax=axes[idx], label=f'{species} (KDE)', \n",
    "                         linewidth=2, color=colors[species])\n",
    "    \n",
    "    axes[idx].set_title(f'KDE Plot: {col}', fontsize=13, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col, fontsize=11)\n",
    "    axes[idx].set_ylabel('Density', fontsize=11)\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bedb1c0",
   "metadata": {},
   "source": [
    "### 3.6 Bar Charts for Statistical Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bbcb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean values comparison across species\n",
    "mean_by_species = df.groupby('species_name')[feature_cols].mean()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(feature_cols):\n",
    "    mean_by_species[col].plot(kind='bar', ax=axes[idx], color=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "                              edgecolor='black', alpha=0.8)\n",
    "    axes[idx].set_title(f'Mean {col} by Species', fontsize=13, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Species', fontsize=11)\n",
    "    axes[idx].set_ylabel(f'Mean {col}', fontsize=11)\n",
    "    axes[idx].set_xticklabels(axes[idx].get_xticklabels(), rotation=45)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5875afd9",
   "metadata": {},
   "source": [
    "### 3.7 Box Plot Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6e2894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots comparing all features side by side\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for idx, species in enumerate(df['species_name'].unique()):\n",
    "    species_data = df[df['species_name'] == species][feature_cols]\n",
    "    bp = axes[idx].boxplot([species_data[col] for col in feature_cols],\n",
    "                           labels=[col.split(' ')[0].capitalize() for col in feature_cols],\n",
    "                           patch_artist=True,\n",
    "                           boxprops=dict(facecolor=colors[species], alpha=0.7),\n",
    "                           medianprops=dict(color='red', linewidth=2))\n",
    "    axes[idx].set_title(f'{species.capitalize()} - Feature Comparison', fontsize=13, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Value (cm)', fontsize=11)\n",
    "    axes[idx].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f70b952",
   "metadata": {},
   "source": [
    "---\n",
    "## SECTION 4: Data Filtering Techniques\n",
    "\n",
    "Filtering is essential for:\n",
    "- Subsetting data based on conditions\n",
    "- Isolating specific classes or features\n",
    "- Removing outliers\n",
    "- Creating focused analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5cf19d",
   "metadata": {},
   "source": [
    "### 4.1 Filter by Feature Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49888e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter 1: Samples with sepal length > 6.0 cm\n",
    "print(\"=\" * 80)\n",
    "print(\"FILTER 1: Sepal Length > 6.0 cm\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "filtered_sepal = df[df['sepal length (cm)'] > 6.0]\n",
    "print(f\"\\nOriginal dataset size: {len(df)}\")\n",
    "print(f\"Filtered dataset size: {len(filtered_sepal)}\")\n",
    "print(f\"Percentage retained: {(len(filtered_sepal) / len(df)) * 100:.2f}%\")\n",
    "print(f\"\\nSpecies distribution in filtered data:\")\n",
    "print(filtered_sepal['species_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75734419",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter 2: Samples with petal width < 0.5 cm\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FILTER 2: Petal Width < 0.5 cm\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "filtered_petal = df[df['petal width (cm)'] < 0.5]\n",
    "print(f\"\\nOriginal dataset size: {len(df)}\")\n",
    "print(f\"Filtered dataset size: {len(filtered_petal)}\")\n",
    "print(f\"Percentage retained: {(len(filtered_petal) / len(df)) * 100:.2f}%\")\n",
    "print(f\"\\nSpecies distribution in filtered data:\")\n",
    "print(filtered_petal['species_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe148434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter 3: Complex condition - Multiple filters combined\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FILTER 3: Complex Condition (Sepal Length > 5.5 AND Petal Length > 4.0)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "filtered_complex = df[(df['sepal length (cm)'] > 5.5) & (df['petal length (cm)'] > 4.0)]\n",
    "print(f\"\\nOriginal dataset size: {len(df)}\")\n",
    "print(f\"Filtered dataset size: {len(filtered_complex)}\")\n",
    "print(f\"Percentage retained: {(len(filtered_complex) / len(df)) * 100:.2f}%\")\n",
    "print(f\"\\nSpecies distribution in filtered data:\")\n",
    "print(filtered_complex['species_name'].value_counts())\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "df['species_name'].value_counts().plot(kind='bar', color='lightblue', edgecolor='black', alpha=0.8)\n",
    "plt.title('Original Data - Species Distribution', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "filtered_complex['species_name'].value_counts().plot(kind='bar', color='coral', edgecolor='black', alpha=0.8)\n",
    "plt.title('Filtered Data - Species Distribution', fontsize=13, fontweight='bold')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd4ef49",
   "metadata": {},
   "source": [
    "### 4.2 Filter by Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef906ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by specific species\n",
    "print(\"=\" * 80)\n",
    "print(\"FILTER BY CLASS LABELS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Get only setosa samples\n",
    "setosa_only = df[df['species_name'] == 'setosa']\n",
    "print(f\"\\nSetosa samples: {len(setosa_only)}\")\n",
    "print(\"\\nSetosa - Statistical Summary:\")\n",
    "print(setosa_only[feature_cols].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get versicolor and virginica (exclude setosa)\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NON-SETOSA SPECIES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "non_setosa = df[df['species_name'] != 'setosa']\n",
    "print(f\"\\nNon-setosa samples: {len(non_setosa)}\")\n",
    "print(\"\\nSpecies distribution:\")\n",
    "print(non_setosa['species_name'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c133726b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple species filter using isin()\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MULTIPLE SPECIES SELECTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "selected_species = df[df['species_name'].isin(['versicolor', 'virginica'])]\n",
    "print(f\"\\nSelected species samples: {len(selected_species)}\")\n",
    "print(\"\\nMean values by species:\")\n",
    "print(selected_species.groupby('species_name')[feature_cols].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34b0b26d",
   "metadata": {},
   "source": [
    "### 4.3 Outlier Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4daaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers using IQR method for a specific feature\n",
    "print(\"=\" * 80)\n",
    "print(\"OUTLIER REMOVAL - Sepal Width\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "Q1 = df['sepal width (cm)'].quantile(0.25)\n",
    "Q3 = df['sepal width (cm)'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out outliers\n",
    "df_no_outliers = df[(df['sepal width (cm)'] >= lower_bound) & (df['sepal width (cm)'] <= upper_bound)]\n",
    "\n",
    "print(f\"\\nOriginal dataset size: {len(df)}\")\n",
    "print(f\"Dataset after outlier removal: {len(df_no_outliers)}\")\n",
    "print(f\"Outliers removed: {len(df) - len(df_no_outliers)}\")\n",
    "\n",
    "# Visualize before and after\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].boxplot(df['sepal width (cm)'], vert=True, patch_artist=True,\n",
    "               boxprops=dict(facecolor='lightblue'))\n",
    "axes[0].set_title('Before Outlier Removal', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylabel('Sepal Width (cm)')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "axes[1].boxplot(df_no_outliers['sepal width (cm)'], vert=True, patch_artist=True,\n",
    "               boxprops=dict(facecolor='lightgreen'))\n",
    "axes[1].set_title('After Outlier Removal', fontsize=13, fontweight='bold')\n",
    "axes[1].set_ylabel('Sepal Width (cm)')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66a4d7a",
   "metadata": {},
   "source": [
    "### 4.4 Feature Selection Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a44a0ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select specific features only\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE SELECTION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Select only petal features\n",
    "petal_features = df[['petal length (cm)', 'petal width (cm)', 'species_name']]\n",
    "print(\"\\nPetal Features Only:\")\n",
    "print(petal_features.head(10))\n",
    "\n",
    "# Select only sepal features\n",
    "sepal_features = df[['sepal length (cm)', 'sepal width (cm)', 'species_name']]\n",
    "print(\"\\nSepal Features Only:\")\n",
    "print(sepal_features.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33228c9b",
   "metadata": {},
   "source": [
    "### 4.5 Quantile-Based Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7a4ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter top 25% of samples by petal length\n",
    "print(\"=\" * 80)\n",
    "print(\"QUANTILE-BASED FILTERING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "petal_length_75th = df['petal length (cm)'].quantile(0.75)\n",
    "top_25_percent = df[df['petal length (cm)'] >= petal_length_75th]\n",
    "\n",
    "print(f\"\\n75th percentile of petal length: {petal_length_75th:.3f} cm\")\n",
    "print(f\"Samples in top 25%: {len(top_25_percent)}\")\n",
    "print(\"\\nSpecies distribution in top 25%:\")\n",
    "print(top_25_percent['species_name'].value_counts())\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df['petal length (cm)'], bins=20, color='lightblue', edgecolor='black', alpha=0.7)\n",
    "plt.axvline(petal_length_75th, color='red', linestyle='--', linewidth=2, label=f'75th percentile: {petal_length_75th:.2f}')\n",
    "plt.title('All Data - Petal Length Distribution', fontsize=13, fontweight='bold')\n",
    "plt.xlabel('Petal Length (cm)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(top_25_percent['petal length (cm)'], bins=15, color='coral', edgecolor='black', alpha=0.7)\n",
    "plt.title('Top 25% - Petal Length Distribution', fontsize=13, fontweight='bold')\n",
    "plt.xlabel('Petal Length (cm)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b877ea7",
   "metadata": {},
   "source": [
    "---\n",
    "## SECTION 5: Statistical Analysis (Correlation & Covariance)\n",
    "\n",
    "Understanding relationships between features through:\n",
    "- Correlation analysis (measures linear relationship strength)\n",
    "- Covariance analysis (measures how variables change together)\n",
    "- Feature redundancy identification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456d2094",
   "metadata": {},
   "source": [
    "### 5.1 Correlation Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4785445f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "print(\"=\" * 80)\n",
    "print(\"CORRELATION MATRIX\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "correlation_matrix = df[feature_cols].corr()\n",
    "print(\"\\n\", correlation_matrix)\n",
    "\n",
    "# Detailed interpretation\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CORRELATION INTERPRETATION\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nStrong Positive Correlations (> 0.7):\")\n",
    "for i in range(len(feature_cols)):\n",
    "    for j in range(i+1, len(feature_cols)):\n",
    "        corr_val = correlation_matrix.iloc[i, j]\n",
    "        if corr_val > 0.7:\n",
    "            print(f\"  {feature_cols[i]} ↔ {feature_cols[j]}: {corr_val:.3f}\")\n",
    "\n",
    "print(\"\\nModerate Correlations (0.4 - 0.7):\")\n",
    "for i in range(len(feature_cols)):\n",
    "    for j in range(i+1, len(feature_cols)):\n",
    "        corr_val = correlation_matrix.iloc[i, j]\n",
    "        if 0.4 <= corr_val <= 0.7:\n",
    "            print(f\"  {feature_cols[i]} ↔ {feature_cols[j]}: {corr_val:.3f}\")\n",
    "\n",
    "print(\"\\nWeak/Negative Correlations (< 0.4):\")\n",
    "for i in range(len(feature_cols)):\n",
    "    for j in range(i+1, len(feature_cols)):\n",
    "        corr_val = correlation_matrix.iloc[i, j]\n",
    "        if corr_val < 0.4:\n",
    "            print(f\"  {feature_cols[i]} ↔ {feature_cols[j]}: {corr_val:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb65361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enhanced correlation heatmap with annotations\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Create mask for upper triangle\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "# Create heatmap\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='RdYlGn', center=0,\n",
    "            square=True, linewidths=2, cbar_kws={\"shrink\": 0.8, \"label\": \"Correlation Coefficient\"},\n",
    "            fmt='.3f', vmin=-1, vmax=1, annot_kws={'size': 11})\n",
    "\n",
    "plt.title('Correlation Heatmap - Lower Triangle', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3cb04b",
   "metadata": {},
   "source": [
    "### 5.2 Covariance Matrix Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8c78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate covariance matrix\n",
    "print(\"=\" * 80)\n",
    "print(\"COVARIANCE MATRIX\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "covariance_matrix = df[feature_cols].cov()\n",
    "print(\"\\n\", covariance_matrix)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COVARIANCE INTERPRETATION\")\n",
    "print(\"=\" *80)\n",
    "print(\"\\nCovariance measures how two variables change together.\")\n",
    "print(\"Positive covariance: variables tend to increase together\")\n",
    "print(\"Negative covariance: when one increases, the other decreases\")\n",
    "print(\"Value magnitude depends on feature scales (unlike correlation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e466c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize covariance matrix\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "sns.heatmap(covariance_matrix, annot=True, cmap='viridis',\n",
    "            square=True, linewidths=2, cbar_kws={\"shrink\": 0.8, \"label\": \"Covariance\"},\n",
    "            fmt='.3f')\n",
    "\n",
    "plt.title('Covariance Heatmap - Iris Features', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ae4c2",
   "metadata": {},
   "source": [
    "### 5.3 Mathematical Relationship: Correlation vs Covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232d408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CORRELATION vs COVARIANCE - MATHEMATICAL RELATIONSHIP\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nFormulas:\")\n",
    "print(\"Covariance(X,Y) = E[(X - μX)(Y - μY)]\")\n",
    "print(\"Correlation(X,Y) = Covariance(X,Y) / (σX * σY)\")\n",
    "print(\"\\nwhere μ = mean, σ = standard deviation, E = expected value\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 80)\n",
    "print(\"Verification for Petal Length and Petal Width:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Manual calculation\n",
    "x = df['petal length (cm)']\n",
    "y = df['petal width (cm)']\n",
    "\n",
    "# Covariance\n",
    "cov_manual = np.sum((x - x.mean()) * (y - y.mean())) / (len(x) - 1)\n",
    "cov_builtin = covariance_matrix.loc['petal length (cm)', 'petal width (cm)']\n",
    "\n",
    "# Correlation\n",
    "corr_manual = cov_manual / (x.std() * y.std())\n",
    "corr_builtin = correlation_matrix.loc['petal length (cm)', 'petal width (cm)']\n",
    "\n",
    "print(f\"\\nCovariance (manual calculation): {cov_manual:.6f}\")\n",
    "print(f\"Covariance (built-in function): {cov_builtin:.6f}\")\n",
    "print(f\"Match: {np.isclose(cov_manual, cov_builtin)}\")\n",
    "\n",
    "print(f\"\\nCorrelation (manual calculation): {corr_manual:.6f}\")\n",
    "print(f\"Correlation (built-in function): {corr_builtin:.6f}\")\n",
    "print(f\"Match: {np.isclose(corr_manual, corr_builtin)}\")\n",
    "\n",
    "print(f\"\\nStandard deviation of Petal Length: {x.std():.6f}\")\n",
    "print(f\"Standard deviation of Petal Width: {y.std():.6f}\")\n",
    "print(f\"Product of std devs: {x.std() * y.std():.6f}\")\n",
    "print(f\"Covariance / (σX * σY) = {cov_manual / (x.std() * y.std()):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bb0574",
   "metadata": {},
   "source": [
    "### 5.4 Feature Redundancy Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd321408",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"FEATURE REDUNDANCY ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Set threshold for high correlation (potential redundancy)\n",
    "threshold = 0.9\n",
    "\n",
    "print(f\"\\nSearching for highly correlated features (correlation > {threshold}):\")\n",
    "high_corr_pairs = []\n",
    "\n",
    "for i in range(len(feature_cols)):\n",
    "    for j in range(i+1, len(feature_cols)):\n",
    "        corr_val = abs(correlation_matrix.iloc[i, j])\n",
    "        if corr_val > threshold:\n",
    "            high_corr_pairs.append((feature_cols[i], feature_cols[j], corr_val))\n",
    "            print(f\"\\n  {feature_cols[i]} ↔ {feature_cols[j]}\")\n",
    "            print(f\"  Correlation: {corr_val:.3f}\")\n",
    "            print(f\"  → Potentially redundant features!\")\n",
    "\n",
    "if not high_corr_pairs:\n",
    "    print(f\"\\n  No feature pairs found with correlation > {threshold}\")\n",
    "    print(\"  This suggests all features provide unique information\")\n",
    "\n",
    "# Check correlation at lower threshold\n",
    "threshold_medium = 0.7\n",
    "print(f\"\\n\\nFeatures with strong correlation (> {threshold_medium}):\")\n",
    "for i in range(len(feature_cols)):\n",
    "    for j in range(i+1, len(feature_cols)):\n",
    "        corr_val = abs(correlation_matrix.iloc[i, j])\n",
    "        if corr_val > threshold_medium:\n",
    "            print(f\"  {feature_cols[i]} ↔ {feature_cols[j]}: {corr_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff2cad5",
   "metadata": {},
   "source": [
    "### 5.5 Pairwise Feature Correlation Plots (F1 vs F2 style)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1fe0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed correlation analysis between specific feature pairs\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "feature_pairs = [\n",
    "    ('sepal length (cm)', 'sepal width (cm)'),\n",
    "    ('sepal length (cm)', 'petal length (cm)'),\n",
    "    ('sepal length (cm)', 'petal width (cm)'),\n",
    "    ('sepal width (cm)', 'petal length (cm)'),\n",
    "    ('sepal width (cm)', 'petal width (cm)'),\n",
    "    ('petal length (cm)', 'petal width (cm)')\n",
    "]\n",
    "\n",
    "for idx, (f1, f2) in enumerate(feature_pairs):\n",
    "    # Scatter plot\n",
    "    for species in df['species_name'].unique():\n",
    "        species_data = df[df['species_name'] == species]\n",
    "        axes[idx].scatter(species_data[f1], species_data[f2],\n",
    "                         label=species, alpha=0.6, s=50, color=colors[species])\n",
    "    \n",
    "    # Calculate and display correlation\n",
    "    corr = df[f1].corr(df[f2])\n",
    "    \n",
    "    # Add regression line\n",
    "    z = np.polyfit(df[f1], df[f2], 1)\n",
    "    p = np.poly1d(z)\n",
    "    axes[idx].plot(df[f1], p(df[f1]), \"r--\", alpha=0.8, linewidth=2)\n",
    "    \n",
    "    axes[idx].set_xlabel(f1, fontsize=10)\n",
    "    axes[idx].set_ylabel(f2, fontsize=10)\n",
    "    axes[idx].set_title(f'{f1.split()[0].capitalize()} vs {f2.split()[0].capitalize()}\\nCorrelation: {corr:.3f}',\n",
    "                       fontsize=11, fontweight='bold')\n",
    "    axes[idx].legend(fontsize=8)\n",
    "    axes[idx].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab06edae",
   "metadata": {},
   "source": [
    "### 5.6 Correlation by Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50918bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation for each species separately\n",
    "print(\"=\" * 80)\n",
    "print(\"CORRELATION ANALYSIS BY SPECIES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for species in df['species_name'].unique():\n",
    "    print(f\"\\n{species.upper()}:\")\n",
    "    print(\"-\" * 40)\n",
    "    species_data = df[df['species_name'] == species][feature_cols]\n",
    "    species_corr = species_data.corr()\n",
    "    print(species_corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb66bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation differences across species\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "for idx, species in enumerate(df['species_name'].unique()):\n",
    "    species_data = df[df['species_name'] == species][feature_cols]\n",
    "    species_corr = species_data.corr()\n",
    "    \n",
    "    sns.heatmap(species_corr, annot=True, cmap='coolwarm', center=0,\n",
    "                square=True, linewidths=1, cbar_kws={\"shrink\": 0.8},\n",
    "                fmt='.2f', vmin=-1, vmax=1, ax=axes[idx])\n",
    "    axes[idx].set_title(f'{species.capitalize()} - Correlation', fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d496181",
   "metadata": {},
   "source": [
    "---\n",
    "## SECTION 6: Sampling Demonstrations\n",
    "\n",
    "Sampling techniques are crucial for:\n",
    "- Creating training/testing datasets\n",
    "- Handling large datasets\n",
    "- Maintaining class proportions\n",
    "- Reducing computational costs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc2be8c",
   "metadata": {},
   "source": [
    "### 6.1 Simple Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e869e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"SIMPLE RANDOM SAMPLING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Take a random sample of 30% of the data\n",
    "sample_size = 0.3\n",
    "random_sample = df.sample(frac=sample_size, random_state=42)\n",
    "\n",
    "print(f\"\\nOriginal dataset size: {len(df)}\")\n",
    "print(f\"Sample size ({sample_size*100}%): {len(random_sample)}\")\n",
    "\n",
    "print(\"\\nOriginal class distribution:\")\n",
    "print(df['species_name'].value_counts())\n",
    "print(\"\\nPercentages:\")\n",
    "print((df['species_name'].value_counts() / len(df)) * 100)\n",
    "\n",
    "print(\"\\nRandom sample class distribution:\")\n",
    "print(random_sample['species_name'].value_counts())\n",
    "print(\"\\nPercentages:\")\n",
    "print((random_sample['species_name'].value_counts() / len(random_sample)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976c00b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distribution comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Original distribution\n",
    "df['species_name'].value_counts().plot(kind='bar', ax=axes[0], \n",
    "                                        color=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "                                        edgecolor='black', alpha=0.8)\n",
    "axes[0].set_title('Original Data - Class Distribution', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xlabel('Species')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Random sample distribution\n",
    "random_sample['species_name'].value_counts().plot(kind='bar', ax=axes[1],\n",
    "                                                   color=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "                                                   edgecolor='black', alpha=0.8)\n",
    "axes[1].set_title(f'Random Sample ({sample_size*100}%) - Class Distribution', fontsize=13, fontweight='bold')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_xlabel('Species')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n⚠ Note: Random sampling may not preserve class proportions perfectly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67698a18",
   "metadata": {},
   "source": [
    "### 6.2 Stratified Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c7aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"STRATIFIED SAMPLING\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nStratified sampling maintains the proportion of each class in the sample\")\n",
    "\n",
    "# Perform stratified sampling\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# We'll use train_test_split with stratification\n",
    "stratified_sample, _ = train_test_split(df, test_size=0.7, stratify=df['species_name'], random_state=42)\n",
    "\n",
    "print(f\"\\nOriginal dataset size: {len(df)}\")\n",
    "print(f\"Stratified sample size (30%): {len(stratified_sample)}\")\n",
    "\n",
    "print(\"\\nOriginal class distribution:\")\n",
    "orig_dist = df['species_name'].value_counts()\n",
    "print(orig_dist)\n",
    "print(\"\\nPercentages:\")\n",
    "print((orig_dist / len(df)) * 100)\n",
    "\n",
    "print(\"\\nStratified sample class distribution:\")\n",
    "strat_dist = stratified_sample['species_name'].value_counts()\n",
    "print(strat_dist)\n",
    "print(\"\\nPercentages:\")\n",
    "print((strat_dist / len(stratified_sample)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbdbe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize stratified sampling\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Original distribution - count\n",
    "df['species_name'].value_counts().plot(kind='bar', ax=axes[0, 0],\n",
    "                                        color=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "                                        edgecolor='black', alpha=0.8)\n",
    "axes[0, 0].set_title('Original - Count', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Count')\n",
    "axes[0, 0].set_xticklabels(axes[0, 0].get_xticklabels(), rotation=45)\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Original distribution - percentage\n",
    "(df['species_name'].value_counts() / len(df) * 100).plot(kind='bar', ax=axes[0, 1],\n",
    "                                                          color=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "                                                          edgecolor='black', alpha=0.8)\n",
    "axes[0, 1].set_title('Original - Percentage', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Percentage (%)')\n",
    "axes[0, 1].set_xticklabels(axes[0, 1].get_xticklabels(), rotation=45)\n",
    "axes[0, 1].set_ylim([0, 40])\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Stratified sample - count\n",
    "stratified_sample['species_name'].value_counts().plot(kind='bar', ax=axes[1, 0],\n",
    "                                                       color=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "                                                       edgecolor='black', alpha=0.8)\n",
    "axes[1, 0].set_title('Stratified Sample - Count', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "axes[1, 0].set_xticklabels(axes[1, 0].get_xticklabels(), rotation=45)\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Stratified sample - percentage\n",
    "(stratified_sample['species_name'].value_counts() / len(stratified_sample) * 100).plot(kind='bar', ax=axes[1, 1],\n",
    "                                                                                         color=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "                                                                                         edgecolor='black', alpha=0.8)\n",
    "axes[1, 1].set_title('Stratified Sample - Percentage', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Percentage (%)')\n",
    "axes[1, 1].set_xticklabels(axes[1, 1].get_xticklabels(), rotation=45)\n",
    "axes[1, 1].set_ylim([0, 40])\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Stratified sampling preserves the class proportions perfectly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b7e800",
   "metadata": {},
   "source": [
    "### 6.3 Hybrid Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4609eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"HYBRID SAMPLING\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nHybrid approach: Combination of stratified sampling with additional random selection\")\n",
    "\n",
    "# Step 1: Stratified sampling to get base sample\n",
    "base_sample, remaining = train_test_split(df, test_size=0.8, stratify=df['species_name'], random_state=42)\n",
    "\n",
    "# Step 2: Add random samples from remaining data\n",
    "additional_random = remaining.sample(n=10, random_state=42)\n",
    "\n",
    "# Combine\n",
    "hybrid_sample = pd.concat([base_sample, additional_random], ignore_index=True)\n",
    "\n",
    "print(f\"\\nOriginal dataset size: {len(df)}\")\n",
    "print(f\"Base stratified sample: {len(base_sample)}\")\n",
    "print(f\"Additional random samples: {len(additional_random)}\")\n",
    "print(f\"Total hybrid sample size: {len(hybrid_sample)}\")\n",
    "\n",
    "print(\"\\nOriginal class distribution:\")\n",
    "print(df['species_name'].value_counts())\n",
    "print(\"\\nPercentages:\")\n",
    "print((df['species_name'].value_counts() / len(df)) * 100)\n",
    "\n",
    "print(\"\\nHybrid sample class distribution:\")\n",
    "print(hybrid_sample['species_name'].value_counts())\n",
    "print(\"\\nPercentages:\")\n",
    "print((hybrid_sample['species_name'].value_counts() / len(hybrid_sample)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c0dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize all three sampling methods\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Original\n",
    "(df['species_name'].value_counts() / len(df) * 100).plot(kind='bar', ax=axes[0, 0],\n",
    "                                                          color=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "                                                          edgecolor='black', alpha=0.8)\n",
    "axes[0, 0].set_title('Original Distribution', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Percentage (%)')\n",
    "axes[0, 0].set_xticklabels(axes[0, 0].get_xticklabels(), rotation=45)\n",
    "axes[0, 0].set_ylim([0, 40])\n",
    "axes[0, 0].axhline(y=33.33, color='red', linestyle='--', linewidth=2, alpha=0.5)\n",
    "axes[0, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Random sample\n",
    "(random_sample['species_name'].value_counts() / len(random_sample) * 100).plot(kind='bar', ax=axes[0, 1],\n",
    "                                                                                 color=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "                                                                                 edgecolor='black', alpha=0.8)\n",
    "axes[0, 1].set_title('Random Sampling', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Percentage (%)')\n",
    "axes[0, 1].set_xticklabels(axes[0, 1].get_xticklabels(), rotation=45)\n",
    "axes[0, 1].set_ylim([0, 40])\n",
    "axes[0, 1].axhline(y=33.33, color='red', linestyle='--', linewidth=2, alpha=0.5)\n",
    "axes[0, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Stratified sample\n",
    "(stratified_sample['species_name'].value_counts() / len(stratified_sample) * 100).plot(kind='bar', ax=axes[1, 0],\n",
    "                                                                                         color=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "                                                                                         edgecolor='black', alpha=0.8)\n",
    "axes[1, 0].set_title('Stratified Sampling', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Percentage (%)')\n",
    "axes[1, 0].set_xticklabels(axes[1, 0].get_xticklabels(), rotation=45)\n",
    "axes[1, 0].set_ylim([0, 40])\n",
    "axes[1, 0].axhline(y=33.33, color='red', linestyle='--', linewidth=2, alpha=0.5)\n",
    "axes[1, 0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Hybrid sample\n",
    "(hybrid_sample['species_name'].value_counts() / len(hybrid_sample) * 100).plot(kind='bar', ax=axes[1, 1],\n",
    "                                                                                 color=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "                                                                                 edgecolor='black', alpha=0.8)\n",
    "axes[1, 1].set_title('Hybrid Sampling', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Percentage (%)')\n",
    "axes[1, 1].set_xticklabels(axes[1, 1].get_xticklabels(), rotation=45)\n",
    "axes[1, 1].set_ylim([0, 40])\n",
    "axes[1, 1].axhline(y=33.33, color='red', linestyle='--', linewidth=2, alpha=0.5, label='Expected (33.33%)')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439a34d4",
   "metadata": {},
   "source": [
    "### 6.4 Sampling Comparison Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a92d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive comparison\n",
    "print(\"=\" * 80)\n",
    "print(\"SAMPLING METHODS COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "sampling_comparison = pd.DataFrame({\n",
    "    'Method': ['Original', 'Random', 'Stratified', 'Hybrid'],\n",
    "    'Total Samples': [len(df), len(random_sample), len(stratified_sample), len(hybrid_sample)],\n",
    "    'Setosa': [\n",
    "        df[df['species_name'] == 'setosa'].shape[0],\n",
    "        random_sample[random_sample['species_name'] == 'setosa'].shape[0],\n",
    "        stratified_sample[stratified_sample['species_name'] == 'setosa'].shape[0],\n",
    "        hybrid_sample[hybrid_sample['species_name'] == 'setosa'].shape[0]\n",
    "    ],\n",
    "    'Versicolor': [\n",
    "        df[df['species_name'] == 'versicolor'].shape[0],\n",
    "        random_sample[random_sample['species_name'] == 'versicolor'].shape[0],\n",
    "        stratified_sample[stratified_sample['species_name'] == 'versicolor'].shape[0],\n",
    "        hybrid_sample[hybrid_sample['species_name'] == 'versicolor'].shape[0]\n",
    "    ],\n",
    "    'Virginica': [\n",
    "        df[df['species_name'] == 'virginica'].shape[0],\n",
    "        random_sample[random_sample['species_name'] == 'virginica'].shape[0],\n",
    "        stratified_sample[stratified_sample['species_name'] == 'virginica'].shape[0],\n",
    "        hybrid_sample[hybrid_sample['species_name'] == 'virginica'].shape[0]\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\n\", sampling_comparison)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"KEY INSIGHTS:\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\n1. Random Sampling:\")\n",
    "print(\"   - Quick and simple\")\n",
    "print(\"   - May not preserve class proportions\")\n",
    "print(\"   - Good for large, balanced datasets\")\n",
    "\n",
    "print(\"\\n2. Stratified Sampling:\")\n",
    "print(\"   - Maintains exact class proportions\")\n",
    "print(\"   - Ideal for imbalanced datasets\")\n",
    "print(\"   - Recommended for train/test splits\")\n",
    "\n",
    "print(\"\\n3. Hybrid Sampling:\")\n",
    "print(\"   - Combines benefits of both methods\")\n",
    "print(\"   - Flexible approach\")\n",
    "print(\"   - Useful for complex sampling requirements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c5190c",
   "metadata": {},
   "source": [
    "---\n",
    "## SECTION 7: Multiclass Classification Data Preparation\n",
    "\n",
    "Preparing data for multiclass classification involves:\n",
    "- Understanding class labels\n",
    "- Encoding categorical variables\n",
    "- Analyzing class balance\n",
    "- Feature scaling considerations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15f465b",
   "metadata": {},
   "source": [
    "### 7.1 Multiclass Label Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463fb3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"MULTICLASS LABEL ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nNumber of classes: {df['species'].nunique()}\")\n",
    "print(f\"Class labels (encoded): {sorted(df['species'].unique())}\")\n",
    "print(f\"Class names: {sorted(df['species_name'].unique())}\")\n",
    "\n",
    "print(\"\\nClass mapping:\")\n",
    "for i in range(df['species'].nunique()):\n",
    "    species_name = df[df['species'] == i]['species_name'].iloc[0]\n",
    "    count = len(df[df['species'] == i])\n",
    "    print(f\"  {i} → {species_name:12s} ({count} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeda861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detailed class statistics\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CLASS-WISE STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for species in df['species_name'].unique():\n",
    "    print(f\"\\n{species.upper()}:\")\n",
    "    print(\"-\" * 40)\n",
    "    species_data = df[df['species_name'] == species][feature_cols]\n",
    "    print(species_data.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9b8c43",
   "metadata": {},
   "source": [
    "### 7.2 Label Encoding Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80e414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"LABEL ENCODING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# The dataset already has encoded labels, but let's demonstrate the process\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a copy for demonstration\n",
    "df_encoded = df.copy()\n",
    "\n",
    "# Initialize label encoder\n",
    "le = LabelEncoder()\n",
    "\n",
    "# Fit and transform\n",
    "df_encoded['species_encoded'] = le.fit_transform(df_encoded['species_name'])\n",
    "\n",
    "print(\"\\nOriginal species names and their encoded values:\")\n",
    "encoding_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "for name, encoded in encoding_map.items():\n",
    "    print(f\"  {name:12s} → {encoded}\")\n",
    "\n",
    "print(\"\\nSample rows showing encoding:\")\n",
    "print(df_encoded[['species_name', 'species', 'species_encoded']].head(10))\n",
    "\n",
    "print(\"\\n✓ Encoding is consistent with original labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef02cc9d",
   "metadata": {},
   "source": [
    "### 7.3 One-Hot Encoding Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b517e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"ONE-HOT ENCODING\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Perform one-hot encoding\n",
    "df_onehot = pd.get_dummies(df['species_name'], prefix='species')\n",
    "\n",
    "print(\"\\nOne-hot encoded representation:\")\n",
    "print(df_onehot.head(10))\n",
    "\n",
    "# Combine with original features\n",
    "df_with_onehot = pd.concat([df[feature_cols], df_onehot], axis=1)\n",
    "\n",
    "print(\"\\nDataset with one-hot encoded labels:\")\n",
    "print(df_with_onehot.head())\n",
    "print(f\"\\nShape: {df_with_onehot.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc982165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize one-hot encoding\n",
    "sample_indices = [0, 50, 100]  # One from each class\n",
    "sample_data = df_onehot.iloc[sample_indices]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "sample_data.T.plot(kind='bar', ax=ax, color=['#FF6B6B', '#4ECDC4', '#45B7D1'], width=0.8)\n",
    "ax.set_title('One-Hot Encoding Visualization (Sample from Each Class)', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Encoded Columns', fontsize=12)\n",
    "ax.set_ylabel('Value', fontsize=12)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "ax.legend([f'Sample {i} ({df.iloc[i][\"species_name\"]})' for i in sample_indices])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c727ae20",
   "metadata": {},
   "source": [
    "### 7.4 Class Balance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0116d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"CLASS BALANCE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Calculate class weights (inverse of frequency)\n",
    "class_counts = df['species_name'].value_counts()\n",
    "total_samples = len(df)\n",
    "n_classes = len(class_counts)\n",
    "\n",
    "class_weights = {}\n",
    "for species in class_counts.index:\n",
    "    weight = total_samples / (n_classes * class_counts[species])\n",
    "    class_weights[species] = weight\n",
    "\n",
    "print(\"\\nClass counts:\")\n",
    "print(class_counts)\n",
    "\n",
    "print(\"\\nClass weights (for handling imbalance):\")\n",
    "for species, weight in class_weights.items():\n",
    "    print(f\"  {species:12s} → {weight:.4f}\")\n",
    "\n",
    "print(\"\\n✓ Dataset is perfectly balanced (all weights ≈ 1.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "907511f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class balance\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Count plot\n",
    "class_counts.plot(kind='bar', ax=axes[0], color=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "                  edgecolor='black', alpha=0.8)\n",
    "axes[0].set_title('Class Distribution - Counts', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xlabel('Species')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45)\n",
    "axes[0].axhline(y=total_samples/n_classes, color='red', linestyle='--', linewidth=2, \n",
    "                label=f'Average ({total_samples/n_classes:.0f})')\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Percentage plot\n",
    "(class_counts / total_samples * 100).plot(kind='bar', ax=axes[1], \n",
    "                                          color=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "                                          edgecolor='black', alpha=0.8)\n",
    "axes[1].set_title('Class Distribution - Percentage', fontsize=13, fontweight='bold')\n",
    "axes[1].set_ylabel('Percentage (%)')\n",
    "axes[1].set_xlabel('Species')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45)\n",
    "axes[1].axhline(y=100/n_classes, color='red', linestyle='--', linewidth=2,\n",
    "                label=f'Average ({100/n_classes:.1f}%)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Class weights plot\n",
    "pd.Series(class_weights).plot(kind='bar', ax=axes[2], color=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "                              edgecolor='black', alpha=0.8)\n",
    "axes[2].set_title('Class Weights', fontsize=13, fontweight='bold')\n",
    "axes[2].set_ylabel('Weight')\n",
    "axes[2].set_xlabel('Species')\n",
    "axes[2].set_xticklabels(axes[2].get_xticklabels(), rotation=45)\n",
    "axes[2].axhline(y=1.0, color='red', linestyle='--', linewidth=2, label='Balanced (1.0)')\n",
    "axes[2].legend()\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b035d1a5",
   "metadata": {},
   "source": [
    "### 7.5 Feature Scaling Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddd1d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"FEATURE SCALING ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nFeature ranges (before scaling):\")\n",
    "for col in feature_cols:\n",
    "    print(f\"  {col:30s}: [{df[col].min():.3f}, {df[col].max():.3f}]  (range: {df[col].max() - df[col].min():.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7f5c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate different scaling techniques (without applying to original data)\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "# Standard Scaling (Z-score normalization)\n",
    "scaler_standard = StandardScaler()\n",
    "df_standard = pd.DataFrame(scaler_standard.fit_transform(df[feature_cols]), \n",
    "                          columns=feature_cols)\n",
    "\n",
    "# Min-Max Scaling\n",
    "scaler_minmax = MinMaxScaler()\n",
    "df_minmax = pd.DataFrame(scaler_minmax.fit_transform(df[feature_cols]),\n",
    "                        columns=feature_cols)\n",
    "\n",
    "# Robust Scaling\n",
    "scaler_robust = RobustScaler()\n",
    "df_robust = pd.DataFrame(scaler_robust.fit_transform(df[feature_cols]),\n",
    "                        columns=feature_cols)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SCALING COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nStandard Scaling (mean=0, std=1):\")\n",
    "print(df_standard.describe())\n",
    "\n",
    "print(\"\\nMin-Max Scaling (range=[0,1]):\")\n",
    "print(df_minmax.describe())\n",
    "\n",
    "print(\"\\nRobust Scaling (using median and IQR):\")\n",
    "print(df_robust.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53898fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scaling effects\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Original data\n",
    "df[feature_cols].boxplot(ax=axes[0, 0])\n",
    "axes[0, 0].set_title('Original Data', fontsize=13, fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Value')\n",
    "axes[0, 0].set_xticklabels([col.split()[0].capitalize() for col in feature_cols], rotation=45)\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Standard scaled\n",
    "df_standard.boxplot(ax=axes[0, 1])\n",
    "axes[0, 1].set_title('Standard Scaling', fontsize=13, fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Standardized Value')\n",
    "axes[0, 1].set_xticklabels([col.split()[0].capitalize() for col in feature_cols], rotation=45)\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Min-Max scaled\n",
    "df_minmax.boxplot(ax=axes[1, 0])\n",
    "axes[1, 0].set_title('Min-Max Scaling', fontsize=13, fontweight='bold')\n",
    "axes[1, 0].set_ylabel('Normalized Value')\n",
    "axes[1, 0].set_xticklabels([col.split()[0].capitalize() for col in feature_cols], rotation=45)\n",
    "axes[1, 0].grid(alpha=0.3)\n",
    "\n",
    "# Robust scaled\n",
    "df_robust.boxplot(ax=axes[1, 1])\n",
    "axes[1, 1].set_title('Robust Scaling', fontsize=13, fontweight='bold')\n",
    "axes[1, 1].set_ylabel('Scaled Value')\n",
    "axes[1, 1].set_xticklabels([col.split()[0].capitalize() for col in feature_cols], rotation=45)\n",
    "axes[1, 1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1632f51",
   "metadata": {},
   "source": [
    "### 7.6 Train-Test Split Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bb2238",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TRAIN-TEST SPLIT PREPARATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Prepare features and labels\n",
    "X = df[feature_cols]\n",
    "y = df['species']\n",
    "\n",
    "print(f\"\\nFeatures (X) shape: {X.shape}\")\n",
    "print(f\"Labels (y) shape: {y.shape}\")\n",
    "\n",
    "# Perform train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                     stratify=y, random_state=42)\n",
    "\n",
    "print(f\"\\nTraining set:\")\n",
    "print(f\"  X_train shape: {X_train.shape}\")\n",
    "print(f\"  y_train shape: {y_train.shape}\")\n",
    "\n",
    "print(f\"\\nTest set:\")\n",
    "print(f\"  X_test shape: {X_test.shape}\")\n",
    "print(f\"  y_test shape: {y_test.shape}\")\n",
    "\n",
    "print(\"\\nClass distribution in training set:\")\n",
    "print(pd.Series(y_train).value_counts().sort_index())\n",
    "\n",
    "print(\"\\nClass distribution in test set:\")\n",
    "print(pd.Series(y_test).value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65c2673b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize train-test split\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Training set distribution\n",
    "train_counts = pd.Series(y_train).map({0: 'setosa', 1: 'versicolor', 2: 'virginica'}).value_counts()\n",
    "train_counts.plot(kind='bar', ax=axes[0], color=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "                  edgecolor='black', alpha=0.8)\n",
    "axes[0].set_title(f'Training Set Distribution (70%)', fontsize=13, fontweight='bold')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xlabel('Species')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45)\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Test set distribution\n",
    "test_counts = pd.Series(y_test).map({0: 'setosa', 1: 'versicolor', 2: 'virginica'}).value_counts()\n",
    "test_counts.plot(kind='bar', ax=axes[1], color=['#FF6B6B', '#4ECDC4', '#45B7D1'],\n",
    "                 edgecolor='black', alpha=0.8)\n",
    "axes[1].set_title(f'Test Set Distribution (30%)', fontsize=13, fontweight='bold')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_xlabel('Species')\n",
    "axes[1].set_xticklabels(axes[1].get_xticklabels(), rotation=45)\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Data is ready for multiclass classification modeling!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f427b122",
   "metadata": {},
   "source": [
    "---\n",
    "## SECTION 8: Summary & Insights\n",
    "\n",
    "Final comprehensive summary of all EDA findings and recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b2efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 100)\n",
    "print(\" \" * 35 + \"EDA SUMMARY & KEY INSIGHTS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(\"\\n1. DATASET OVERVIEW:\")\n",
    "print(\"   \" + \"-\" * 90)\n",
    "print(f\"   • Total samples: {len(df)}\")\n",
    "print(f\"   • Number of features: {len(feature_cols)}\")\n",
    "print(f\"   • Number of classes: {df['species'].nunique()}\")\n",
    "print(f\"   • Missing values: {df.isnull().sum().sum()} (Perfect data quality!)\")\n",
    "print(f\"   • Duplicate rows: {df.duplicated().sum()}\")\n",
    "\n",
    "print(\"\\n2. CLASS DISTRIBUTION:\")\n",
    "print(\"   \" + \"-\" * 90)\n",
    "print(\"   • Perfectly balanced dataset (50 samples per class)\")\n",
    "print(\"   • Setosa: 50 samples (33.33%)\")\n",
    "print(\"   • Versicolor: 50 samples (33.33%)\")\n",
    "print(\"   • Virginica: 50 samples (33.33%)\")\n",
    "print(\"   ✓ No class imbalance handling required\")\n",
    "\n",
    "print(\"\\n3. FEATURE CHARACTERISTICS:\")\n",
    "print(\"   \" + \"-\" * 90)\n",
    "for col in feature_cols:\n",
    "    print(f\"   • {col}:\")\n",
    "    print(f\"     Range: [{df[col].min():.2f}, {df[col].max():.2f}]  |  Mean: {df[col].mean():.2f}  |  Std: {df[col].std():.2f}\")\n",
    "\n",
    "print(\"\\n4. CORRELATION INSIGHTS:\")\n",
    "print(\"   \" + \"-\" * 90)\n",
    "print(\"   Strong correlations found:\")\n",
    "for i in range(len(feature_cols)):\n",
    "    for j in range(i+1, len(feature_cols)):\n",
    "        corr_val = correlation_matrix.iloc[i, j]\n",
    "        if abs(corr_val) > 0.8:\n",
    "            print(f\"   • {feature_cols[i]} ↔ {feature_cols[j]}: {corr_val:.3f} (Very Strong)\")\n",
    "        elif abs(corr_val) > 0.7:\n",
    "            print(f\"   • {feature_cols[i]} ↔ {feature_cols[j]}: {corr_val:.3f} (Strong)\")\n",
    "\n",
    "print(\"\\n5. OUTLIER ANALYSIS:\")\n",
    "print(\"   \" + \"-\" * 90)\n",
    "print(\"   • Minimal outliers detected using IQR method\")\n",
    "print(\"   • Most outliers found in sepal width feature\")\n",
    "print(\"   • Outliers are species-specific and biologically meaningful\")\n",
    "print(\"   ✓ No outlier removal recommended\")\n",
    "\n",
    "print(\"\\n6. FEATURE SEPARABILITY:\")\n",
    "print(\"   \" + \"-\" * 90)\n",
    "print(\"   • Setosa is highly separable from other species (especially in petal features)\")\n",
    "print(\"   • Versicolor and Virginica show some overlap\")\n",
    "print(\"   • Petal length and petal width are the most discriminative features\")\n",
    "print(\"   • Sepal features show more overlap between classes\")\n",
    "\n",
    "print(\"\\n7. SAMPLING EVALUATION:\")\n",
    "print(\"   \" + \"-\" * 90)\n",
    "print(\"   • Random sampling: Quick but may not preserve proportions\")\n",
    "print(\"   • Stratified sampling: Recommended for train/test splits (maintains class balance)\")\n",
    "print(\"   • Hybrid sampling: Flexible for complex requirements\")\n",
    "\n",
    "print(\"\\n8. DATA QUALITY ASSESSMENT:\")\n",
    "print(\"   \" + \"-\" * 90)\n",
    "print(\"   ✓ No missing values\")\n",
    "print(\"   ✓ No duplicate rows\")\n",
    "print(\"   ✓ All features are numeric (float64)\")\n",
    "print(\"   ✓ Perfect class balance\")\n",
    "print(\"   ✓ Reasonable feature ranges\")\n",
    "print(\"   ✓ No data type issues\")\n",
    "\n",
    "print(\"\\n9. RECOMMENDATIONS FOR MODELING:\")\n",
    "print(\"   \" + \"-\" * 90)\n",
    "print(\"   • Use stratified sampling for train/test split to maintain class proportions\")\n",
    "print(\"   • Consider feature scaling (StandardScaler or MinMaxScaler) for distance-based algorithms\")\n",
    "print(\"   • Petal features should have higher importance in classification\")\n",
    "print(\"   • No need for class balancing techniques\")\n",
    "print(\"   • All features can be used (no redundancy issues)\")\n",
    "print(\"   • Consider both linear and non-linear models (data shows good separability)\")\n",
    "\n",
    "print(\"\\n10. KEY STATISTICAL FINDINGS:\")\n",
    "print(\"   \" + \"-\" * 90)\n",
    "print(f\"   • Highest correlation: Petal length ↔ Petal width ({correlation_matrix.loc['petal length (cm)', 'petal width (cm)']:.3f})\")\n",
    "print(f\"   • Feature with largest range: Petal length ({df['petal length (cm)'].max() - df['petal length (cm)'].min():.2f} cm)\")\n",
    "print(f\"   • Most variable feature: Petal length (σ = {df['petal length (cm)'].std():.2f})\")\n",
    "print(f\"   • Least variable feature: Sepal width (σ = {df['sepal width (cm)'].std():.2f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\" \" * 30 + \"END OF EXPLORATORY DATA ANALYSIS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(\"\\n✓ EDA Complete! Dataset is ready for machine learning modeling.\")\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"  1. Feature engineering (if needed)\")\n",
    "print(\"  2. Model selection and training\")\n",
    "print(\"  3. Model evaluation and tuning\")\n",
    "print(\"  4. Performance comparison across different algorithms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7057b1",
   "metadata": {},
   "source": [
    "---\n",
    "## Visualizations Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af777f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a final comprehensive visualization\n",
    "fig = plt.figure(figsize=(20, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Class distribution\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "df['species_name'].value_counts().plot(kind='bar', ax=ax1, color=['#FF6B6B', '#4ECDC4', '#45B7D1'], \n",
    "                                        edgecolor='black', alpha=0.8)\n",
    "ax1.set_title('Class Distribution', fontsize=12, fontweight='bold')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.set_xticklabels(ax1.get_xticklabels(), rotation=45)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. Correlation heatmap (compact)\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, ax=ax2,\n",
    "            square=True, cbar_kws={\"shrink\": 0.8}, fmt='.2f', vmin=-1, vmax=1)\n",
    "ax2.set_title('Feature Correlations', fontsize=12, fontweight='bold')\n",
    "\n",
    "# 3. Feature distributions\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "for col in feature_cols:\n",
    "    df[col].plot(kind='kde', ax=ax3, label=col.split()[0].capitalize(), linewidth=2)\n",
    "ax3.set_title('Feature Density Distributions', fontsize=12, fontweight='bold')\n",
    "ax3.set_xlabel('Value')\n",
    "ax3.set_ylabel('Density')\n",
    "ax3.legend(fontsize=9)\n",
    "ax3.grid(alpha=0.3)\n",
    "\n",
    "# 4. Petal Length vs Width scatter\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "for species in df['species_name'].unique():\n",
    "    species_data = df[df['species_name'] == species]\n",
    "    ax4.scatter(species_data['petal length (cm)'], species_data['petal width (cm)'],\n",
    "               label=species, alpha=0.6, s=50, color=colors[species], edgecolors='black')\n",
    "ax4.set_title('Petal Length vs Width', fontsize=12, fontweight='bold')\n",
    "ax4.set_xlabel('Petal Length (cm)')\n",
    "ax4.set_ylabel('Petal Width (cm)')\n",
    "ax4.legend(fontsize=9)\n",
    "ax4.grid(alpha=0.3)\n",
    "\n",
    "# 5. Box plots\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "df[feature_cols].boxplot(ax=ax5)\n",
    "ax5.set_title('Feature Box Plots', fontsize=12, fontweight='bold')\n",
    "ax5.set_ylabel('Value (cm)')\n",
    "ax5.set_xticklabels([col.split()[0].capitalize() for col in feature_cols], rotation=45)\n",
    "ax5.grid(alpha=0.3)\n",
    "\n",
    "# 6. Mean comparison\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "mean_by_species.plot(kind='bar', ax=ax6, width=0.8)\n",
    "ax6.set_title('Mean Feature Values by Species', fontsize=12, fontweight='bold')\n",
    "ax6.set_ylabel('Mean Value (cm)')\n",
    "ax6.set_xlabel('Species')\n",
    "ax6.set_xticklabels(ax6.get_xticklabels(), rotation=45)\n",
    "ax6.legend(title='Features', fontsize=8, title_fontsize=9, loc='upper left')\n",
    "ax6.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 7-9. Individual feature distributions by species\n",
    "feature_indices = [0, 2]  # Sepal length and Petal length\n",
    "for idx, feat_idx in enumerate(feature_indices):\n",
    "    ax = fig.add_subplot(gs[2, idx])\n",
    "    col = feature_cols[feat_idx]\n",
    "    for species in df['species_name'].unique():\n",
    "        species_data = df[df['species_name'] == species][col]\n",
    "        species_data.plot(kind='kde', ax=ax, label=species, linewidth=2, alpha=0.7)\n",
    "    ax.set_title(f'{col} by Species', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel(col)\n",
    "    ax.set_ylabel('Density')\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "# Last plot - sampling comparison\n",
    "ax9 = fig.add_subplot(gs[2, 2])\n",
    "sampling_methods = ['Original', 'Random', 'Stratified']\n",
    "sampling_sizes = [len(df), len(random_sample), len(stratified_sample)]\n",
    "ax9.bar(sampling_methods, sampling_sizes, color=['#FF6B6B', '#4ECDC4', '#45B7D1'], \n",
    "        edgecolor='black', alpha=0.8)\n",
    "ax9.set_title('Sampling Methods Comparison', fontsize=12, fontweight='bold')\n",
    "ax9.set_ylabel('Sample Size')\n",
    "ax9.set_xlabel('Method')\n",
    "ax9.grid(axis='y', alpha=0.3)\n",
    "\n",
    "fig.suptitle('Comprehensive EDA Summary - Iris Dataset', fontsize=18, fontweight='bold', y=0.995)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"✓ Comprehensive EDA visualization complete!\")\n",
    "print(\"=\" * 100)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
